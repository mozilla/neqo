name: Bench
on:
  workflow_call:
  workflow_dispatch:
env:
  CARGO_PROFILE_BENCH_BUILD_OVERRIDE_DEBUG: true
  CARGO_PROFILE_RELEASE_DEBUG: true
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  TOOLCHAIN: nightly
  RUSTFLAGS: -C link-arg=-fuse-ld=lld -C link-arg=-Wl,--no-rosegment, -C force-frame-pointers=yes
  PERF_CMD: record -o perf.data -F997 --call-graph fp -g

jobs:
  bench:
    name: Benchmark
    runs-on: self-hosted
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout neqo
        uses: actions/checkout@v4

      - name: Checkout msquic
        uses: actions/checkout@v4
        with:
          repository: microsoft/msquic
          ref: main
          path: msquic
          submodules: true

      - name: Set PATH
        run: echo "/home/bench/.cargo/bin" >> "${GITHUB_PATH}"

      - name: Install Rust
        uses: ./.github/actions/rust
        with:
          version: $TOOLCHAIN
          components: rustfmt

      - name: Fetch and build NSS and NSPR
        uses: ./.github/actions/nss

      - name: Build neqo
        run: |
          cargo "+$TOOLCHAIN" bench --features bench --no-run
          cargo "+$TOOLCHAIN" build --release --bin neqo-client --bin neqo-server

      - name: Build msquic
        run: |
          mkdir -p msquic/build
          cd msquic/build
          cmake -GNinja -DQUIC_BUILD_TOOLS=1 -DQUIC_BUILD_PERF=1 ..
          cmake --build .

      - name: Download cached main-branch results
        id: criterion-cache
        uses: actions/cache/restore@v4
        with:
          path: ./target/criterion
          key: criterion-${{ runner.name }}-${{ github.sha }}
          restore-keys: criterion-${{ runner.name }}-

      # Disable turboboost, hyperthreading and use performance governor.
      - name: Prepare machine
        run: sudo /root/bin/prep.sh

      # Pin the benchmark run to core 0 and run all benchmarks at elevated priority.
      - name: Run cargo bench
        run: |
          taskset -c 0 nice -n -20 \
            cargo "+$TOOLCHAIN" bench --features bench -- --noplot | tee results.txt

      # Pin the transfer benchmark to core 0 and run it at elevated priority inside perf.
      # Work around https://github.com/flamegraph-rs/flamegraph/issues/248 by passing explicit perf arguments.
      - name: Profile cargo bench transfer
        run: |
          # This re-runs part of the previous step, and would hence overwrite part of the criterion results.
          # Avoid that by shuffling the directories around so this run uses its own results directory.
          mv target/criterion target/criterion-bench
          mv target/criterion-transfer-profile target/criterion || true
          taskset -c 0 nice -n -20 \
            cargo "+$TOOLCHAIN" flamegraph -v -c "$PERF_CMD" --features bench --bench transfer -- \
              --bench --exact "Run multiple transfers with varying seeds" --noplot
          # And now restore the directories.
          mv target/criterion target/criterion-transfer-profile
          mv target/criterion-bench target/criterion

      - name: Profile client/server transfer
        run: |
          { mkdir server; \
            cd server; \
            taskset -c 0 nice -n -20 \
            cargo "+$TOOLCHAIN" flamegraph -v -c "$PERF_CMD" \
              --bin neqo-server -- --db ../test-fixture/db "$HOST:4433" || true; } &
          mkdir client; \
            cd client; \
            time taskset -c 1 nice -n -20 \
            cargo "+$TOOLCHAIN" flamegraph -v -c "$PERF_CMD" \
              --bin neqo-client -- --output-dir . "https://$HOST:4433/$SIZE"
          killall -INT neqo-server
          cd ${{ github.workspace }}
          [ "$(wc -c < client/"$SIZE")" -eq "$SIZE" ] || exit 1
        env:
          HOST: localhost
          SIZE: 1073741824 # 1 GB

      - name: Compare neqo and msquic
        env:
          HOST: 127.0.0.1
          PORT: 4433
          SIZE: 67108864 # 64 MB
        run: |
          TMPDIR=$(mktemp -d)
          openssl req -nodes -new -x509 -keyout "$TMP/key" -out "$TMP/cert" -subj "/CN=DOMAIN" 2> /dev/null
          truncate -s "$SIZE" "/tmp/$SIZE"
          declare -A client_cmd=(
            ["neqo"]="target/release/neqo-client -o -a hq-interop -Q 1 https://localhost:4433/$SIZE"
            ["msquic"]="msquic/build/bin/Release/quicinterop -test:D -timeout:99999999 -custom:$HOST -port:$PORT -urls:https://$HOST:$SIZE/"
          )
          declare -A server_cmd=(
            ["neqo"]="target/release/neqo-server -o -a hq-interop -Q 1 $HOST:$PORT"
            ["msquic"]="msquic/build/bin/Release/quicinteropserver -root:$TMP -listen:$HOST -port:$PORT -file:$TMP/cert -key:$TMP/key -noexit"
          )
          for server in neqo msquic; do
            ${server_cmd["$server"]} &
            PID=$!
            echo "Running teste for ${server} server" | tee -a comparison.txt
            hyperfine -n "$server" -L client neqo,msquic--export-markdown comparison.md "${client_cmd["{client}"]}" | tee -a comparison.txt || true
            echo >> comparison.txt
            kill $PID
            cat comparison.md >> "$GITHUB_STEP_SUMMARY"
          done
          rm -r "$TMP"

      # Re-enable turboboost, hyperthreading and use powersave governor.
      - name: Restore machine
        run: sudo /root/bin/unprep.sh
        if: success() || failure() || cancelled()

      - name: Convert for profiler.firefox.com
        run: |
          perf script -i perf.data -F +pid > transfer.perf &
          perf script -i client/perf.data -F +pid > client.perf &
          perf script -i server/perf.data -F +pid > server.perf &
          wait
          mv flamegraph.svg transfer.svg
          mv client/flamegraph.svg client.svg
          mv server/flamegraph.svg server.svg
          rm neqo.svg

      - name: Generate perf reports
        run: |
          perf report -i perf.data --no-children --stdio > transfer.perf.txt &
          perf report -i client/perf.data --no-children --stdio > client.perf.txt &
          perf report -i server/perf.data --no-children --stdio > server.perf.txt &
          wait

      - name: Format results as Markdown
        id: results
        run: |
          {
            echo "### Benchmark results"
            echo
          } > results.md
          SHA=$(cat target/criterion/baseline-sha.txt)
          if [ -n "$SHA" ]; then
            {
              echo "Performance differences relative to $SHA."
              echo
            } >> results.md
          fi
          grep -Ev 'ignored|running \d+ tests|%\)' results.txt |\
            sed -E  -e 's/(Performance has regressed.)/:broken_heart: **\1**/gi' \
                    -e 's/(Performance has improved.)/:green_heart: **\1**/gi' \
                    -e 's/^ +/   /gi' \
                    -e 's/^([a-z0-9].*)$/* **\1**/gi' \
                    -e 's/(change:[^%]*% )([^%]*%)(.*)/\1**\2**\3/gi' \
              >> results.md

      - name: Remember main-branch push URL
        if: github.ref == 'refs/heads/main'
        run: echo "${{ github.sha }}" > target/criterion/baseline-sha.txt

      - name: Store history
        if: github.ref == 'refs/heads/main'
        run: |
          mkdir -p target/criterion-history
          cp -r target/criterion "target/criterion-history/$(date +%s)-${{ github.sha }}"

      - name: Cache main-branch results
        if: github.ref == 'refs/heads/main'
        uses: actions/cache/save@v4
        with:
          path: ./target/criterion
          key: criterion-${{ runner.name }}-${{ github.sha }}

      - name: Export perf data
        id: export
        uses: actions/upload-artifact@v4
        with:
          name: ${{ github.event.repository.name }}-${{ github.sha }}
          path: |
            *.svg
            *.perf
            *.txt
            results.*
            target/criterion*
          compression-level: 9

      - name: Export PR comment data
        uses: ./.github/actions/pr-comment-data-export
        with:
          name: bench
          contents: results.md
          log-url: ${{ steps.export.outputs.artifact-url }}
